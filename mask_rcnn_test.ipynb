{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:47:58.286198Z",
     "start_time": "2025-01-28T19:47:23.346376Z"
    }
   },
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py' 'work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth' --show",
   "id": "463e37e1a55f59bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\r\n",
      "  from torch.distributed.optim import \\\r\n",
      "01/28 13:47:29 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 208531918\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\r\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\r\n",
      "    PyTorch: 2.4.1+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 90.1  (built against CUDA 12.4)\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.19.1+cu121\r\n",
      "    OpenCV: 4.11.0\r\n",
      "    MMEngine: 0.10.6\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 208531918\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "01/28 13:47:29 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\r\n",
      "backend_args = None\r\n",
      "data_root = 'data/swd/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(\r\n",
      "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(\r\n",
      "        draw=True, show=True, type='DetVisualizationHook', wait_time=2))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "metainfo = dict(\r\n",
      "    classes='swd', palette=[\r\n",
      "        (\r\n",
      "            220,\r\n",
      "            20,\r\n",
      "            60,\r\n",
      "        ),\r\n",
      "    ])\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        depth=101,\r\n",
      "        frozen_stages=1,\r\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet101', type='Pretrained'),\r\n",
      "        norm_cfg=dict(requires_grad=False, type='BN'),\r\n",
      "        norm_eval=True,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        style='caffe',\r\n",
      "        type='ResNet'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=False,\r\n",
      "        mean=[\r\n",
      "            103.53,\r\n",
      "            116.28,\r\n",
      "            123.675,\r\n",
      "        ],\r\n",
      "        pad_mask=True,\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            1.0,\r\n",
      "            1.0,\r\n",
      "            1.0,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        in_channels=[\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "            1024,\r\n",
      "            2048,\r\n",
      "        ],\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        type='FPN'),\r\n",
      "    roi_head=dict(\r\n",
      "        bbox_head=dict(\r\n",
      "            bbox_coder=dict(\r\n",
      "                target_means=[\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                ],\r\n",
      "                target_stds=[\r\n",
      "                    0.1,\r\n",
      "                    0.1,\r\n",
      "                    0.2,\r\n",
      "                    0.2,\r\n",
      "                ],\r\n",
      "                type='DeltaXYWHBBoxCoder'),\r\n",
      "            fc_out_channels=1024,\r\n",
      "            in_channels=256,\r\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "            loss_cls=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\r\n",
      "            num_classes=1,\r\n",
      "            reg_class_agnostic=False,\r\n",
      "            roi_feat_size=7,\r\n",
      "            type='Shared2FCBBoxHead'),\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        mask_head=dict(\r\n",
      "            conv_out_channels=256,\r\n",
      "            in_channels=256,\r\n",
      "            loss_mask=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\r\n",
      "            num_classes=1,\r\n",
      "            num_convs=4,\r\n",
      "            type='FCNMaskHead'),\r\n",
      "        mask_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        type='StandardRoIHead'),\r\n",
      "    rpn_head=dict(\r\n",
      "        anchor_generator=dict(\r\n",
      "            ratios=[\r\n",
      "                0.5,\r\n",
      "                1.0,\r\n",
      "                2.0,\r\n",
      "            ],\r\n",
      "            scales=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "                64,\r\n",
      "            ],\r\n",
      "            type='AnchorGenerator'),\r\n",
      "        bbox_coder=dict(\r\n",
      "            target_means=[\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "            ],\r\n",
      "            target_stds=[\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "            ],\r\n",
      "            type='DeltaXYWHBBoxCoder'),\r\n",
      "        feat_channels=256,\r\n",
      "        in_channels=256,\r\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\r\n",
      "        type='RPNHead'),\r\n",
      "    test_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            mask_thr_binary=0.5,\r\n",
      "            max_per_img=100,\r\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\r\n",
      "            score_thr=0.05),\r\n",
      "        rpn=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=1000)),\r\n",
      "    train_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            mask_size=28,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=True,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn=dict(\r\n",
      "            allowed_border=-1,\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=False,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=2000)),\r\n",
      "    type='MaskRCNN')\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(lr=0.001, momentum=0.9, type='SGD', weight_decay=0.0001),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        end=12,\r\n",
      "        gamma=0.1,\r\n",
      "        milestones=[\r\n",
      "            8,\r\n",
      "            11,\r\n",
      "        ],\r\n",
      "        type='MultiStepLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test/test.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='test/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/swd/test/test.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\r\n",
      "    batch_size=4,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='train/train.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                poly2mask=False,\r\n",
      "                type='LoadAnnotations',\r\n",
      "                with_bbox=True,\r\n",
      "                with_mask=True),\r\n",
      "            dict(\r\n",
      "                keep_ratio=True,\r\n",
      "                scales=[\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        640,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        672,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        704,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        736,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        768,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        800,\r\n",
      "                    ),\r\n",
      "                ],\r\n",
      "                type='RandomChoiceResize'),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        poly2mask=False,\r\n",
      "        type='LoadAnnotations',\r\n",
      "        with_bbox=True,\r\n",
      "        with_mask=True),\r\n",
      "    dict(\r\n",
      "        keep_ratio=True,\r\n",
      "        scales=[\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                640,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                672,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                704,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                736,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                768,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ),\r\n",
      "        ],\r\n",
      "        type='RandomChoiceResize'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='val/val.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/swd/val/val.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "    dict(type='TensorboardVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "        dict(type='TensorboardVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco'\r\n",
      "\r\n",
      "2025-01-28 13:47:30.824235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n",
      "01/28 13:47:33 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmdet/engine/hooks/visualization_hook.py:68: UserWarning: The show is True, it means that only the prediction results are visualized without storing data, so vis_backends needs to be excluded.\r\n",
      "  warnings.warn('The show is True, it means that only '\r\n",
      "01/28 13:47:33 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "01/28 13:47:34 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - swd is not a meta file, simply parsed as meta information\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\r\n",
      "01/28 13:47:35 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Load checkpoint from work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:760: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image\r\n",
      "  warnings.warn(\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:831: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image\r\n",
      "  warnings.warn(\r\n",
      "01/28 13:47:54 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Epoch(test) [50/57]    eta: 0:00:02  time: 0.3734  data_time: 0.2588  memory: 470  \r\n",
      "01/28 13:47:56 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.01s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.01s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.542\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.829\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.558\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.139\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.595\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.629\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.629\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.629\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.237\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.687\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "01/28 13:47:56 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| swd      | 0.542 | 0.829  | 0.558  | 0.139 | 0.595 | nan   |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "01/28 13:47:56 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - bbox_mAP_copypaste: 0.542 0.829 0.558 0.139 0.595 -1.000\r\n",
      "01/28 13:47:56 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Evaluating segm...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *segm*\r\n",
      "DONE (t=0.01s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.00s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.838\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.515\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.097\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.525\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.553\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.553\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.553\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.225\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.602\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "01/28 13:47:56 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| swd      | 0.477 | 0.838  | 0.515  | 0.097 | 0.525 | nan   |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "01/28 13:47:56 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - segm_mAP_copypaste: 0.477 0.838 0.515 0.097 0.525 -1.000\r\n",
      "01/28 13:47:56 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Epoch(test) [57/57]    coco/swd_precision: 0.4770  coco/bbox_mAP: 0.5420  coco/bbox_mAP_50: 0.8290  coco/bbox_mAP_75: 0.5580  coco/bbox_mAP_s: 0.1390  coco/bbox_mAP_m: 0.5950  coco/bbox_mAP_l: -1.0000  coco/segm_mAP: 0.4770  coco/segm_mAP_50: 0.8380  coco/segm_mAP_75: 0.5150  coco/segm_mAP_s: 0.0970  coco/segm_mAP_m: 0.5250  coco/segm_mAP_l: -1.0000  data_time: 0.2602  time: 0.3723\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py' 'work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth' --show",
   "id": "a65769e9b45f04ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py' 'work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth' --show",
   "id": "58a923d2d1550ecc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py' 'work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth' --show",
   "id": "d64d63a039fc39f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py' 'work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth' --show",
   "id": "9bb5e10dcad6093",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py' 'work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth' --show",
   "id": "ff40388ecc5e67b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py' 'work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth' --show",
   "id": "6b1fc80d642d9c12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py' 'work_dirs/early_0120/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco_batch1_300epoch/best_coco_swd_precision_epoch_15.pth' --show",
   "id": "730bced1c815f23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2",
   "id": "eb28629d4a667b1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:51:53.028539Z",
     "start_time": "2025-01-27T20:51:18.100705Z"
    }
   },
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py' 'work_dirs/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco/best_coco_swd_precision_epoch_90.pth' --show --work-dir work_dirs/results --out work_dirs/results/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.pkl",
   "id": "113fafcd37a1de16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\r\n",
      "  from torch.distributed.optim import \\\r\n",
      "01/27 14:51:22 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 1948244541\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\r\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\r\n",
      "    PyTorch: 2.4.1+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 90.1  (built against CUDA 12.4)\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.19.1+cu121\r\n",
      "    OpenCV: 4.11.0\r\n",
      "    MMEngine: 0.10.6\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1948244541\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "01/27 14:51:22 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\r\n",
      "backend_args = None\r\n",
      "data_root = 'data/swd/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(\r\n",
      "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(\r\n",
      "        draw=True, show=True, type='DetVisualizationHook', wait_time=2))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'work_dirs/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco/best_coco_swd_precision_epoch_90.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "metainfo = dict(\r\n",
      "    classes='swd', palette=[\r\n",
      "        (\r\n",
      "            220,\r\n",
      "            20,\r\n",
      "            60,\r\n",
      "        ),\r\n",
      "    ])\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        depth=101,\r\n",
      "        frozen_stages=1,\r\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet101', type='Pretrained'),\r\n",
      "        norm_cfg=dict(requires_grad=False, type='BN'),\r\n",
      "        norm_eval=True,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        style='caffe',\r\n",
      "        type='ResNet'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=False,\r\n",
      "        mean=[\r\n",
      "            103.53,\r\n",
      "            116.28,\r\n",
      "            123.675,\r\n",
      "        ],\r\n",
      "        pad_mask=True,\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            1.0,\r\n",
      "            1.0,\r\n",
      "            1.0,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        in_channels=[\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "            1024,\r\n",
      "            2048,\r\n",
      "        ],\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        type='FPN'),\r\n",
      "    roi_head=dict(\r\n",
      "        bbox_head=dict(\r\n",
      "            bbox_coder=dict(\r\n",
      "                target_means=[\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                ],\r\n",
      "                target_stds=[\r\n",
      "                    0.1,\r\n",
      "                    0.1,\r\n",
      "                    0.2,\r\n",
      "                    0.2,\r\n",
      "                ],\r\n",
      "                type='DeltaXYWHBBoxCoder'),\r\n",
      "            fc_out_channels=1024,\r\n",
      "            in_channels=256,\r\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "            loss_cls=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\r\n",
      "            num_classes=1,\r\n",
      "            reg_class_agnostic=False,\r\n",
      "            roi_feat_size=7,\r\n",
      "            type='Shared2FCBBoxHead'),\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        mask_head=dict(\r\n",
      "            conv_out_channels=256,\r\n",
      "            in_channels=256,\r\n",
      "            loss_mask=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\r\n",
      "            num_classes=1,\r\n",
      "            num_convs=4,\r\n",
      "            type='FCNMaskHead'),\r\n",
      "        mask_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        type='StandardRoIHead'),\r\n",
      "    rpn_head=dict(\r\n",
      "        anchor_generator=dict(\r\n",
      "            ratios=[\r\n",
      "                0.5,\r\n",
      "                1.0,\r\n",
      "                2.0,\r\n",
      "            ],\r\n",
      "            scales=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "                64,\r\n",
      "            ],\r\n",
      "            type='AnchorGenerator'),\r\n",
      "        bbox_coder=dict(\r\n",
      "            target_means=[\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "            ],\r\n",
      "            target_stds=[\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "            ],\r\n",
      "            type='DeltaXYWHBBoxCoder'),\r\n",
      "        feat_channels=256,\r\n",
      "        in_channels=256,\r\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\r\n",
      "        type='RPNHead'),\r\n",
      "    test_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            mask_thr_binary=0.5,\r\n",
      "            max_per_img=100,\r\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\r\n",
      "            score_thr=0.05),\r\n",
      "        rpn=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=1000)),\r\n",
      "    train_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            mask_size=28,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=True,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn=dict(\r\n",
      "            allowed_border=-1,\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=False,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=2000)),\r\n",
      "    type='MaskRCNN')\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(lr=0.001, momentum=0.9, type='SGD', weight_decay=0.0001),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        end=12,\r\n",
      "        gamma=0.1,\r\n",
      "        milestones=[\r\n",
      "            8,\r\n",
      "            11,\r\n",
      "        ],\r\n",
      "        type='MultiStepLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test/test.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='test/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/swd/test/test.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\r\n",
      "    batch_size=4,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='train/train.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                poly2mask=False,\r\n",
      "                type='LoadAnnotations',\r\n",
      "                with_bbox=True,\r\n",
      "                with_mask=True),\r\n",
      "            dict(\r\n",
      "                keep_ratio=True,\r\n",
      "                scales=[\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        640,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        672,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        704,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        736,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        768,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        800,\r\n",
      "                    ),\r\n",
      "                ],\r\n",
      "                type='RandomChoiceResize'),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        poly2mask=False,\r\n",
      "        type='LoadAnnotations',\r\n",
      "        with_bbox=True,\r\n",
      "        with_mask=True),\r\n",
      "    dict(\r\n",
      "        keep_ratio=True,\r\n",
      "        scales=[\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                640,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                672,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                704,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                736,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                768,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ),\r\n",
      "        ],\r\n",
      "        type='RandomChoiceResize'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='val/val.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/swd/val/val.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "    dict(type='TensorboardVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "        dict(type='TensorboardVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = 'work_dirs/results'\r\n",
      "\r\n",
      "2025-01-27 14:51:23.382749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n",
      "01/27 14:51:26 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmdet/engine/hooks/visualization_hook.py:68: UserWarning: The show is True, it means that only the prediction results are visualized without storing data, so vis_backends needs to be excluded.\r\n",
      "  warnings.warn('The show is True, it means that only '\r\n",
      "01/27 14:51:26 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "01/27 14:51:26 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - swd is not a meta file, simply parsed as meta information\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "01/27 14:51:26 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - The prefix is not set in metric class DumpDetResults.\r\n",
      "Loads checkpoint by local backend from path: work_dirs/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco/best_coco_swd_precision_epoch_90.pth\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\r\n",
      "01/27 14:51:28 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Load checkpoint from work_dirs/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco/best_coco_swd_precision_epoch_90.pth\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:760: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image\r\n",
      "  warnings.warn(\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:831: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image\r\n",
      "  warnings.warn(\r\n",
      "01/27 14:51:48 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Epoch(test) [50/57]    eta: 0:00:02  time: 0.4008  data_time: 0.2712  memory: 470  \r\n",
      "01/27 14:51:51 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.02s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.01s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.616\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.316\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.288\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.350\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.556\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.556\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.556\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.475\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.569\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "01/27 14:51:51 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| swd      | 0.334 | 0.616  | 0.316  | 0.288 | 0.35  | nan   |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "01/27 14:51:51 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - bbox_mAP_copypaste: 0.334 0.616 0.316 0.288 0.350 -1.000\r\n",
      "01/27 14:51:51 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Evaluating segm...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *segm*\r\n",
      "DONE (t=0.02s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.01s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.623\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.358\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.226\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.381\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.547\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.547\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.537\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.548\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "01/27 14:51:51 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| swd      | 0.333 | 0.623  | 0.358  | 0.226 | 0.381 | nan   |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "01/27 14:51:51 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - segm_mAP_copypaste: 0.333 0.623 0.358 0.226 0.381 -1.000\r\n",
      "01/27 14:51:51 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Results has been saved to work_dirs/results/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.pkl.\r\n",
      "01/27 14:51:51 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Epoch(test) [57/57]    coco/swd_precision: 0.3330  coco/bbox_mAP: 0.3340  coco/bbox_mAP_50: 0.6160  coco/bbox_mAP_75: 0.3160  coco/bbox_mAP_s: 0.2880  coco/bbox_mAP_m: 0.3500  coco/bbox_mAP_l: -1.0000  coco/segm_mAP: 0.3330  coco/segm_mAP_50: 0.6230  coco/segm_mAP_75: 0.3580  coco/segm_mAP_s: 0.2260  coco/segm_mAP_m: 0.3810  coco/segm_mAP_l: -1.0000  data_time: 0.2728  time: 0.3982\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:57:24.298326Z",
     "start_time": "2025-01-27T20:57:19.583526Z"
    }
   },
   "cell_type": "code",
   "source": "!python tools/analysis_tools/confusion_matrix.py 'work_dirs/results/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py'  'work_dirs/results/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.pkl'  'work_dirs/results' --show",
   "id": "24453b51cdc61064",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\r\n",
      "  from torch.distributed.optim import \\\r\n",
      "01/27 14:57:23 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - swd is not a meta file, simply parsed as meta information\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 4661.2 task/s, elapsed: 0s, ETA:     0stools/analysis_tools/confusion_matrix.py:173: RuntimeWarning: invalid value encountered in divide\r\n",
      "  confusion_matrix.astype(np.float32) / per_label_sums * 100\r\n",
      "tools/analysis_tools/confusion_matrix.py:229: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\r\n",
      "  fig.tight_layout()\r\n",
      "Figure(180x144)\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T19:53:35.721150Z",
     "start_time": "2025-01-27T19:53:04.918257Z"
    }
   },
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r50_fpn_1x_coco.py' 'work_dirs/mask-rcnn_r50_fpn_1x_coco/best_coco_swd_precision_epoch_90.pth' --show",
   "id": "ae40bab2f0bda12a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\r\n",
      "  from torch.distributed.optim import \\\r\n",
      "01/27 13:53:08 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 2024999962\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\r\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\r\n",
      "    PyTorch: 2.4.1+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 90.1  (built against CUDA 12.4)\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.19.1+cu121\r\n",
      "    OpenCV: 4.11.0\r\n",
      "    MMEngine: 0.10.6\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 2024999962\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "01/27 13:53:09 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\r\n",
      "backend_args = None\r\n",
      "data_root = 'data/swd/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(\r\n",
      "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(\r\n",
      "        draw=True, show=True, type='DetVisualizationHook', wait_time=2))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'work_dirs/mask-rcnn_r50_fpn_1x_coco/best_coco_swd_precision_epoch_90.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "metainfo = dict(\r\n",
      "    classes='swd', palette=[\r\n",
      "        (\r\n",
      "            220,\r\n",
      "            20,\r\n",
      "            60,\r\n",
      "        ),\r\n",
      "    ])\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        depth=50,\r\n",
      "        frozen_stages=1,\r\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\r\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\r\n",
      "        norm_eval=True,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        style='pytorch',\r\n",
      "        type='ResNet'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=True,\r\n",
      "        mean=[\r\n",
      "            123.675,\r\n",
      "            116.28,\r\n",
      "            103.53,\r\n",
      "        ],\r\n",
      "        pad_mask=True,\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            58.395,\r\n",
      "            57.12,\r\n",
      "            57.375,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        in_channels=[\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "            1024,\r\n",
      "            2048,\r\n",
      "        ],\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        type='FPN'),\r\n",
      "    roi_head=dict(\r\n",
      "        bbox_head=dict(\r\n",
      "            bbox_coder=dict(\r\n",
      "                target_means=[\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                ],\r\n",
      "                target_stds=[\r\n",
      "                    0.1,\r\n",
      "                    0.1,\r\n",
      "                    0.2,\r\n",
      "                    0.2,\r\n",
      "                ],\r\n",
      "                type='DeltaXYWHBBoxCoder'),\r\n",
      "            fc_out_channels=1024,\r\n",
      "            in_channels=256,\r\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "            loss_cls=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\r\n",
      "            num_classes=1,\r\n",
      "            reg_class_agnostic=False,\r\n",
      "            roi_feat_size=7,\r\n",
      "            type='Shared2FCBBoxHead'),\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        mask_head=dict(\r\n",
      "            conv_out_channels=256,\r\n",
      "            in_channels=256,\r\n",
      "            loss_mask=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\r\n",
      "            num_classes=1,\r\n",
      "            num_convs=4,\r\n",
      "            type='FCNMaskHead'),\r\n",
      "        mask_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        type='StandardRoIHead'),\r\n",
      "    rpn_head=dict(\r\n",
      "        anchor_generator=dict(\r\n",
      "            ratios=[\r\n",
      "                0.5,\r\n",
      "                1.0,\r\n",
      "                2.0,\r\n",
      "            ],\r\n",
      "            scales=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "                64,\r\n",
      "            ],\r\n",
      "            type='AnchorGenerator'),\r\n",
      "        bbox_coder=dict(\r\n",
      "            target_means=[\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "            ],\r\n",
      "            target_stds=[\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "            ],\r\n",
      "            type='DeltaXYWHBBoxCoder'),\r\n",
      "        feat_channels=256,\r\n",
      "        in_channels=256,\r\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\r\n",
      "        type='RPNHead'),\r\n",
      "    test_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            mask_thr_binary=0.5,\r\n",
      "            max_per_img=100,\r\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\r\n",
      "            score_thr=0.05),\r\n",
      "        rpn=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=1000)),\r\n",
      "    train_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            mask_size=28,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=True,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn=dict(\r\n",
      "            allowed_border=-1,\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=False,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=2000)),\r\n",
      "    type='MaskRCNN')\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(lr=0.001, momentum=0.9, type='SGD', weight_decay=0.0001),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        end=12,\r\n",
      "        gamma=0.1,\r\n",
      "        milestones=[\r\n",
      "            8,\r\n",
      "            11,\r\n",
      "        ],\r\n",
      "        type='MultiStepLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test/test.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='test/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/swd/test/test.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\r\n",
      "    batch_size=4,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='train/train.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='val/val.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/swd/val/val.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "    dict(type='TensorboardVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "        dict(type='TensorboardVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/mask-rcnn_r50_fpn_1x_coco'\r\n",
      "\r\n",
      "2025-01-27 13:53:09.591389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n",
      "01/27 13:53:11 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmdet/engine/hooks/visualization_hook.py:68: UserWarning: The show is True, it means that only the prediction results are visualized without storing data, so vis_backends needs to be excluded.\r\n",
      "  warnings.warn('The show is True, it means that only '\r\n",
      "01/27 13:53:11 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "01/27 13:53:11 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - swd is not a meta file, simply parsed as meta information\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: work_dirs/mask-rcnn_r50_fpn_1x_coco/best_coco_swd_precision_epoch_90.pth\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\r\n",
      "01/27 13:53:12 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Load checkpoint from work_dirs/mask-rcnn_r50_fpn_1x_coco/best_coco_swd_precision_epoch_90.pth\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:760: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image\r\n",
      "  warnings.warn(\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:831: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image\r\n",
      "  warnings.warn(\r\n",
      "01/27 13:53:31 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Epoch(test) [50/57]    eta: 0:00:02  time: 0.3834  data_time: 0.2792  memory: 398  \r\n",
      "01/27 13:53:34 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.02s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.01s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.719\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.440\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.374\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.473\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.621\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.621\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.621\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.475\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.643\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "01/27 13:53:34 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| swd      | 0.453 | 0.719  | 0.44   | 0.374 | 0.473 | nan   |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "01/27 13:53:34 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - bbox_mAP_copypaste: 0.453 0.719 0.440 0.374 0.473 -1.000\r\n",
      "01/27 13:53:34 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Evaluating segm...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *segm*\r\n",
      "DONE (t=0.01s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.01s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.719\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.470\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.192\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.520\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.637\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.637\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.463\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.663\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "01/27 13:53:34 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| swd      | 0.461 | 0.719  | 0.47   | 0.192 | 0.52  | nan   |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "01/27 13:53:34 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - segm_mAP_copypaste: 0.461 0.719 0.470 0.192 0.520 -1.000\r\n",
      "01/27 13:53:34 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Epoch(test) [57/57]    coco/swd_precision: 0.4610  coco/bbox_mAP: 0.4530  coco/bbox_mAP_50: 0.7190  coco/bbox_mAP_75: 0.4400  coco/bbox_mAP_s: 0.3740  coco/bbox_mAP_m: 0.4730  coco/bbox_mAP_l: -1.0000  coco/segm_mAP: 0.4610  coco/segm_mAP_50: 0.7190  coco/segm_mAP_75: 0.4700  coco/segm_mAP_s: 0.1920  coco/segm_mAP_m: 0.5200  coco/segm_mAP_l: -1.0000  data_time: 0.2761  time: 0.3783\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T19:54:08.353906Z",
     "start_time": "2025-01-27T19:53:35.748277Z"
    }
   },
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_r101_fpn_1x_coco.py' 'work_dirs/mask-rcnn_r101_fpn_1x_coco/best_coco_swd_precision_epoch_55.pth' --show",
   "id": "705faa3dc071a711",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\r\n",
      "  from torch.distributed.optim import \\\r\n",
      "01/27 13:53:40 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 1199639056\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\r\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\r\n",
      "    PyTorch: 2.4.1+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 90.1  (built against CUDA 12.4)\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.19.1+cu121\r\n",
      "    OpenCV: 4.11.0\r\n",
      "    MMEngine: 0.10.6\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1199639056\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "01/27 13:53:40 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\r\n",
      "backend_args = None\r\n",
      "data_root = 'data/swd/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(\r\n",
      "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(\r\n",
      "        draw=True, show=True, type='DetVisualizationHook', wait_time=2))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'work_dirs/mask-rcnn_r101_fpn_1x_coco/best_coco_swd_precision_epoch_55.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "metainfo = dict(\r\n",
      "    classes='swd', palette=[\r\n",
      "        (\r\n",
      "            220,\r\n",
      "            20,\r\n",
      "            60,\r\n",
      "        ),\r\n",
      "    ])\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        depth=101,\r\n",
      "        frozen_stages=1,\r\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet101', type='Pretrained'),\r\n",
      "        norm_cfg=dict(requires_grad=False, type='BN'),\r\n",
      "        norm_eval=True,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        style='caffe',\r\n",
      "        type='ResNet'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=False,\r\n",
      "        mean=[\r\n",
      "            103.53,\r\n",
      "            116.28,\r\n",
      "            123.675,\r\n",
      "        ],\r\n",
      "        pad_mask=True,\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            1.0,\r\n",
      "            1.0,\r\n",
      "            1.0,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        in_channels=[\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "            1024,\r\n",
      "            2048,\r\n",
      "        ],\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        type='FPN'),\r\n",
      "    roi_head=dict(\r\n",
      "        bbox_head=dict(\r\n",
      "            bbox_coder=dict(\r\n",
      "                target_means=[\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                ],\r\n",
      "                target_stds=[\r\n",
      "                    0.1,\r\n",
      "                    0.1,\r\n",
      "                    0.2,\r\n",
      "                    0.2,\r\n",
      "                ],\r\n",
      "                type='DeltaXYWHBBoxCoder'),\r\n",
      "            fc_out_channels=1024,\r\n",
      "            in_channels=256,\r\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "            loss_cls=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\r\n",
      "            num_classes=1,\r\n",
      "            reg_class_agnostic=False,\r\n",
      "            roi_feat_size=7,\r\n",
      "            type='Shared2FCBBoxHead'),\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        mask_head=dict(\r\n",
      "            conv_out_channels=256,\r\n",
      "            in_channels=256,\r\n",
      "            loss_mask=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\r\n",
      "            num_classes=1,\r\n",
      "            num_convs=4,\r\n",
      "            type='FCNMaskHead'),\r\n",
      "        mask_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        type='StandardRoIHead'),\r\n",
      "    rpn_head=dict(\r\n",
      "        anchor_generator=dict(\r\n",
      "            ratios=[\r\n",
      "                0.5,\r\n",
      "                1.0,\r\n",
      "                2.0,\r\n",
      "            ],\r\n",
      "            scales=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "                64,\r\n",
      "            ],\r\n",
      "            type='AnchorGenerator'),\r\n",
      "        bbox_coder=dict(\r\n",
      "            target_means=[\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "            ],\r\n",
      "            target_stds=[\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "            ],\r\n",
      "            type='DeltaXYWHBBoxCoder'),\r\n",
      "        feat_channels=256,\r\n",
      "        in_channels=256,\r\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\r\n",
      "        type='RPNHead'),\r\n",
      "    test_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            mask_thr_binary=0.5,\r\n",
      "            max_per_img=100,\r\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\r\n",
      "            score_thr=0.05),\r\n",
      "        rpn=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=1000)),\r\n",
      "    train_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            mask_size=28,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=True,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn=dict(\r\n",
      "            allowed_border=-1,\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=False,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=2000)),\r\n",
      "    type='MaskRCNN')\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(lr=0.001, momentum=0.9, type='SGD', weight_decay=0.0001),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        end=12,\r\n",
      "        gamma=0.1,\r\n",
      "        milestones=[\r\n",
      "            8,\r\n",
      "            11,\r\n",
      "        ],\r\n",
      "        type='MultiStepLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test/test.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='test/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/swd/test/test.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\r\n",
      "    batch_size=4,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='train/train.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                poly2mask=False,\r\n",
      "                type='LoadAnnotations',\r\n",
      "                with_bbox=True,\r\n",
      "                with_mask=True),\r\n",
      "            dict(\r\n",
      "                keep_ratio=True,\r\n",
      "                scales=[\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        640,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        672,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        704,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        736,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        768,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        800,\r\n",
      "                    ),\r\n",
      "                ],\r\n",
      "                type='RandomChoiceResize'),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        poly2mask=False,\r\n",
      "        type='LoadAnnotations',\r\n",
      "        with_bbox=True,\r\n",
      "        with_mask=True),\r\n",
      "    dict(\r\n",
      "        keep_ratio=True,\r\n",
      "        scales=[\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                640,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                672,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                704,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                736,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                768,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ),\r\n",
      "        ],\r\n",
      "        type='RandomChoiceResize'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='val/val.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/swd/val/val.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "    dict(type='TensorboardVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "        dict(type='TensorboardVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/mask-rcnn_r101_fpn_1x_coco'\r\n",
      "\r\n",
      "2025-01-27 13:53:40.847588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n",
      "01/27 13:53:42 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmdet/engine/hooks/visualization_hook.py:68: UserWarning: The show is True, it means that only the prediction results are visualized without storing data, so vis_backends needs to be excluded.\r\n",
      "  warnings.warn('The show is True, it means that only '\r\n",
      "01/27 13:53:42 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "01/27 13:53:43 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - swd is not a meta file, simply parsed as meta information\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: work_dirs/mask-rcnn_r101_fpn_1x_coco/best_coco_swd_precision_epoch_55.pth\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\r\n",
      "01/27 13:53:44 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Load checkpoint from work_dirs/mask-rcnn_r101_fpn_1x_coco/best_coco_swd_precision_epoch_55.pth\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:760: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image\r\n",
      "  warnings.warn(\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:831: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image\r\n",
      "  warnings.warn(\r\n",
      "01/27 13:54:04 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Epoch(test) [50/57]    eta: 0:00:02  time: 0.3914  data_time: 0.2754  memory: 843  \r\n",
      "01/27 13:54:06 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.03s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.01s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.299\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.152\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.188\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.365\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.365\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.013\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.417\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "01/27 13:54:06 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| swd      | 0.148 | 0.299  | 0.152  | 0.0   | 0.188 | nan   |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "01/27 13:54:06 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - bbox_mAP_copypaste: 0.148 0.299 0.152 0.000 0.188 -1.000\r\n",
      "01/27 13:54:06 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Evaluating segm...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *segm*\r\n",
      "DONE (t=0.04s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.01s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.345\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.093\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.234\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.403\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.403\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.163\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.439\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "01/27 13:54:07 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "+----------+------+--------+--------+-------+-------+-------+\r\n",
      "| category | mAP  | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+----------+------+--------+--------+-------+-------+-------+\r\n",
      "| swd      | 0.15 | 0.345  | 0.093  | 0.002 | 0.234 | nan   |\r\n",
      "+----------+------+--------+--------+-------+-------+-------+\r\n",
      "01/27 13:54:07 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - segm_mAP_copypaste: 0.150 0.345 0.093 0.002 0.234 -1.000\r\n",
      "01/27 13:54:07 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Epoch(test) [57/57]    coco/swd_precision: 0.1500  coco/bbox_mAP: 0.1480  coco/bbox_mAP_50: 0.2990  coco/bbox_mAP_75: 0.1520  coco/bbox_mAP_s: 0.0000  coco/bbox_mAP_m: 0.1880  coco/bbox_mAP_l: -1.0000  coco/segm_mAP: 0.1500  coco/segm_mAP_50: 0.3450  coco/segm_mAP_75: 0.0930  coco/segm_mAP_s: 0.0020  coco/segm_mAP_m: 0.2340  coco/segm_mAP_l: -1.0000  data_time: 0.2773  time: 0.3908\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T19:59:10.957991Z",
     "start_time": "2025-01-27T19:58:38.414151Z"
    }
   },
   "cell_type": "code",
   "source": "!python tools/test.py 'configs/swd/mask-rcnn_x101-32x4d_fpn_1x_coco.py' 'work_dirs/mask-rcnn_x101-32x4d_fpn_1x_coco/best_coco_swd_precision_epoch_95.pth' --show",
   "id": "a2b67729706793e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\r\n",
      "  from torch.distributed.optim import \\\r\n",
      "01/27 13:58:42 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 2107775332\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\r\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\r\n",
      "    PyTorch: 2.4.1+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 90.1  (built against CUDA 12.4)\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.19.1+cu121\r\n",
      "    OpenCV: 4.11.0\r\n",
      "    MMEngine: 0.10.6\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 2107775332\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "01/27 13:58:42 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\r\n",
      "backend_args = None\r\n",
      "data_root = 'data/swd/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(\r\n",
      "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(\r\n",
      "        draw=True, show=True, type='DetVisualizationHook', wait_time=2))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'work_dirs/mask-rcnn_x101-32x4d_fpn_1x_coco/best_coco_swd_precision_epoch_95.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "metainfo = dict(\r\n",
      "    classes='swd', palette=[\r\n",
      "        (\r\n",
      "            220,\r\n",
      "            20,\r\n",
      "            60,\r\n",
      "        ),\r\n",
      "    ])\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        base_width=4,\r\n",
      "        depth=101,\r\n",
      "        frozen_stages=1,\r\n",
      "        groups=32,\r\n",
      "        init_cfg=dict(\r\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\r\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\r\n",
      "        norm_eval=True,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        style='pytorch',\r\n",
      "        type='ResNeXt'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=False,\r\n",
      "        mean=[\r\n",
      "            103.53,\r\n",
      "            116.28,\r\n",
      "            123.675,\r\n",
      "        ],\r\n",
      "        pad_mask=True,\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            1.0,\r\n",
      "            1.0,\r\n",
      "            1.0,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        in_channels=[\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "            1024,\r\n",
      "            2048,\r\n",
      "        ],\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        type='FPN'),\r\n",
      "    roi_head=dict(\r\n",
      "        bbox_head=dict(\r\n",
      "            bbox_coder=dict(\r\n",
      "                target_means=[\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                ],\r\n",
      "                target_stds=[\r\n",
      "                    0.1,\r\n",
      "                    0.1,\r\n",
      "                    0.2,\r\n",
      "                    0.2,\r\n",
      "                ],\r\n",
      "                type='DeltaXYWHBBoxCoder'),\r\n",
      "            fc_out_channels=1024,\r\n",
      "            in_channels=256,\r\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "            loss_cls=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\r\n",
      "            num_classes=1,\r\n",
      "            reg_class_agnostic=False,\r\n",
      "            roi_feat_size=7,\r\n",
      "            type='Shared2FCBBoxHead'),\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        mask_head=dict(\r\n",
      "            conv_out_channels=256,\r\n",
      "            in_channels=256,\r\n",
      "            loss_mask=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\r\n",
      "            num_classes=1,\r\n",
      "            num_convs=4,\r\n",
      "            type='FCNMaskHead'),\r\n",
      "        mask_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        type='StandardRoIHead'),\r\n",
      "    rpn_head=dict(\r\n",
      "        anchor_generator=dict(\r\n",
      "            ratios=[\r\n",
      "                0.5,\r\n",
      "                1.0,\r\n",
      "                2.0,\r\n",
      "            ],\r\n",
      "            scales=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "                64,\r\n",
      "            ],\r\n",
      "            type='AnchorGenerator'),\r\n",
      "        bbox_coder=dict(\r\n",
      "            target_means=[\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "            ],\r\n",
      "            target_stds=[\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "            ],\r\n",
      "            type='DeltaXYWHBBoxCoder'),\r\n",
      "        feat_channels=256,\r\n",
      "        in_channels=256,\r\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\r\n",
      "        type='RPNHead'),\r\n",
      "    test_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            mask_thr_binary=0.5,\r\n",
      "            max_per_img=100,\r\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\r\n",
      "            score_thr=0.05),\r\n",
      "        rpn=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=1000)),\r\n",
      "    train_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            mask_size=28,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=True,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn=dict(\r\n",
      "            allowed_border=-1,\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=False,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=2000)),\r\n",
      "    type='MaskRCNN')\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(lr=0.001, momentum=0.9, type='SGD', weight_decay=0.0001),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        end=12,\r\n",
      "        gamma=0.1,\r\n",
      "        milestones=[\r\n",
      "            8,\r\n",
      "            11,\r\n",
      "        ],\r\n",
      "        type='MultiStepLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test/test.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='test/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/swd/test/test.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\r\n",
      "    batch_size=4,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='train/train.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                poly2mask=False,\r\n",
      "                type='LoadAnnotations',\r\n",
      "                with_bbox=True,\r\n",
      "                with_mask=True),\r\n",
      "            dict(\r\n",
      "                keep_ratio=True,\r\n",
      "                scales=[\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        640,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        672,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        704,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        736,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        768,\r\n",
      "                    ),\r\n",
      "                    (\r\n",
      "                        1333,\r\n",
      "                        800,\r\n",
      "                    ),\r\n",
      "                ],\r\n",
      "                type='RandomChoiceResize'),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        poly2mask=False,\r\n",
      "        type='LoadAnnotations',\r\n",
      "        with_bbox=True,\r\n",
      "        with_mask=True),\r\n",
      "    dict(\r\n",
      "        keep_ratio=True,\r\n",
      "        scales=[\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                640,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                672,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                704,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                736,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                768,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ),\r\n",
      "        ],\r\n",
      "        type='RandomChoiceResize'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='val/val.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val/'),\r\n",
      "        data_root='data/swd/',\r\n",
      "        metainfo=dict(classes='swd', palette=[\r\n",
      "            (\r\n",
      "                220,\r\n",
      "                20,\r\n",
      "                60,\r\n",
      "            ),\r\n",
      "        ]),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/swd/val/val.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "    dict(type='TensorboardVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "        dict(type='TensorboardVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/mask-rcnn_x101-32x4d_fpn_1x_coco'\r\n",
      "\r\n",
      "2025-01-27 13:58:43.307378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n",
      "01/27 13:58:45 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmdet/engine/hooks/visualization_hook.py:68: UserWarning: The show is True, it means that only the prediction results are visualized without storing data, so vis_backends needs to be excluded.\r\n",
      "  warnings.warn('The show is True, it means that only '\r\n",
      "01/27 13:58:45 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "01/27 13:58:45 - mmengine - \u001B[5m\u001B[4m\u001B[33mWARNING\u001B[0m - swd is not a meta file, simply parsed as meta information\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: work_dirs/mask-rcnn_x101-32x4d_fpn_1x_coco/best_coco_swd_precision_epoch_95.pth\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\r\n",
      "01/27 13:58:46 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Load checkpoint from work_dirs/mask-rcnn_x101-32x4d_fpn_1x_coco/best_coco_swd_precision_epoch_95.pth\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:760: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image\r\n",
      "  warnings.warn(\r\n",
      "/home/tianqi/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:831: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image\r\n",
      "  warnings.warn(\r\n",
      "01/27 13:59:06 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Epoch(test) [50/57]    eta: 0:00:02  time: 0.3928  data_time: 0.2732  memory: 840  \r\n",
      "01/27 13:59:09 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.03s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.01s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.430\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.164\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.275\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.474\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.474\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.037\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.539\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "01/27 13:59:09 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| swd      | 0.231 | 0.43   | 0.164  | 0.0   | 0.275 | nan   |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "01/27 13:59:09 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - bbox_mAP_copypaste: 0.231 0.430 0.164 0.000 0.275 -1.000\r\n",
      "01/27 13:59:09 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Evaluating segm...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *segm*\r\n",
      "DONE (t=0.04s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.02s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.430\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.159\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.285\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.455\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.455\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.113\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.506\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "01/27 13:59:09 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - \r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "| swd      | 0.217 | 0.43   | 0.159  | 0.0   | 0.285 | nan   |\r\n",
      "+----------+-------+--------+--------+-------+-------+-------+\r\n",
      "01/27 13:59:09 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - segm_mAP_copypaste: 0.217 0.430 0.159 0.000 0.285 -1.000\r\n",
      "01/27 13:59:09 - mmengine - \u001B[4m\u001B[37mINFO\u001B[0m - Epoch(test) [57/57]    coco/swd_precision: 0.2170  coco/bbox_mAP: 0.2310  coco/bbox_mAP_50: 0.4300  coco/bbox_mAP_75: 0.1640  coco/bbox_mAP_s: 0.0000  coco/bbox_mAP_m: 0.2750  coco/bbox_mAP_l: -1.0000  coco/segm_mAP: 0.2170  coco/segm_mAP_50: 0.4300  coco/segm_mAP_75: 0.1590  coco/segm_mAP_s: 0.0000  coco/segm_mAP_m: 0.2850  coco/segm_mAP_l: -1.0000  data_time: 0.2760  time: 0.3926\r\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
